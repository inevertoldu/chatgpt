{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8382e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/heavenly/opt/anaconda3/envs/flask/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7947ef",
   "metadata": {},
   "source": [
    "# ChatGPT API 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8abb0",
   "metadata": {},
   "source": [
    "### ChatGPT API를 이용하기 위해서는..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371e56a",
   "metadata": {},
   "source": [
    "1. ChatGPT API Key 발급<br>\n",
    "2. 가상환경 설치(anaconda)<br>\n",
    "3. Python 및 필요한 라이브러리 설치: pip install [패키지명]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ab5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import openai\n",
    "import markdown\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c633abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "your API Key(starting with sk-) ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass('your API Key(starting with sk-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2010ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.1 # 값의 범위는 0부터~ (값이 작으면 자유도가 낮아진다.)\n",
    "MAX_TOKENS = 4096  # GPT-3.5의 최대 토큰 길이임(입력, 출력 동일함)\n",
    "MODEL = 'gpt-3.5-turbo-0613'\n",
    "# MODEL = 'gpt-3.5-turbo-16k'\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "context = [] # 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1ef78",
   "metadata": {},
   "source": [
    "## 대화형 인공지능의 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tokens(items):\n",
    "    cnt = 0\n",
    "\n",
    "    if items is None:\n",
    "        return cnt\n",
    "\n",
    "    for item in items:\n",
    "        cnt += len(item['content'])\n",
    "\n",
    "    return cnt\n",
    "\n",
    "def conversate():\n",
    "    while(1):\n",
    "        message = input('대화:')\n",
    "        message = message.strip()\n",
    "    \n",
    "        if message == '':\n",
    "            print('대화 내용을 입력하세요.')\n",
    "            continue\n",
    "        elif message == 'exit':\n",
    "            break\n",
    "    \n",
    "        # 대화 맥락을 고려하여 전체 최대 토큰을 초과하는지 체크하도록 한다.\n",
    "        total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "        if total_cnt >= MAX_TOKENS:\n",
    "            context.clear()\n",
    "            print('context cleared.')\n",
    "\n",
    "        # ChatGPT 대화를 위한 메시지 형태 설정하기\n",
    "        if len(context) == 0:\n",
    "            context.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        response = openai.ChatCompletion.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "        print(f\"AI: {answer}\")\n",
    "        #codes = markdown.markdown(answer, extensions=['fenced_code', 'codehilite'])\n",
    "        context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "        if check_tokens(context) >= MAX_TOKENS:\n",
    "            context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5c70bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "대화: 안녕\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 안녕하세요! 도움이 필요하신가요?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "대화: 반가워\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 저도 반가워요! 무엇을 도와드릴까요?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "대화: 1부터 100까지 더해 봐\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 1부터 100까지 더하는 방법은 간단합니다. 모든 숫자를 하나씩 더해가면 됩니다. 하지만 이 방법은 시간이 오래 걸릴 수 있습니다. 좀 더 빠른 방법은 등차수열의 합 공식을 사용하는 것입니다.\n",
      "\n",
      "1부터 n까지의 합은 다음과 같은 공식으로 구할 수 있습니다:\n",
      "합 = (n * (n + 1)) / 2\n",
      "\n",
      "따라서 1부터 100까지의 합은 다음과 같이 계산할 수 있습니다:\n",
      "합 = (100 * (100 + 1)) / 2 = 5050\n",
      "\n",
      "따라서 1부터 100까지의 합은 5050입니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "대화: 이걸 파이썬 코드로 만들어 줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 물론입니다! 파이썬 코드로 1부터 100까지의 합을 구하는 방법은 다음과 같습니다:\n",
      "\n",
      "```python\n",
      "total = 0\n",
      "for i in range(1, 101):\n",
      "    total += i\n",
      "\n",
      "print(total)\n",
      "```\n",
      "\n",
      "이 코드를 실행하면 1부터 100까지의 합인 5050이 출력됩니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "대화: exit\n"
     ]
    }
   ],
   "source": [
    "conversate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce03015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ask(message):\n",
    "    message = message.strip()\n",
    "\n",
    "    if message == '':\n",
    "        print('대화 내용을 입력하세요.')\n",
    "    elif message == 'exit':\n",
    "        return\n",
    "\n",
    "    # 대화 맥락을 고려하여 전체 최대 토큰을 초과하는지 체크하도록 한다.\n",
    "    total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "    if total_cnt >= MAX_TOKENS:\n",
    "        context.clear()\n",
    "        print('context cleared.')\n",
    "\n",
    "    # ChatGPT 대화를 위한 메시지 형태 설정하기\n",
    "    if len(context) == 0:\n",
    "        context.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "        context.append({\"role\": \"user\", \"content\": message})\n",
    "    else:\n",
    "        context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    print(f\"AI: {answer}\")\n",
    "    #codes = markdown.markdown(answer, extensions=['fenced_code', 'codehilite'])\n",
    "    context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "    if check_tokens(context) >= MAX_TOKENS:\n",
    "        context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3926a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 1부터 100까지의 숫자 중 소수를 찾는 파이썬 코드는 다음과 같습니다:\n",
      "\n",
      "```python\n",
      "def is_prime(num):\n",
      "    if num < 2:\n",
      "        return False\n",
      "    for i in range(2, int(num**0.5) + 1):\n",
      "        if num % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "prime_numbers = []\n",
      "for num in range(1, 101):\n",
      "    if is_prime(num):\n",
      "        prime_numbers.append(num)\n",
      "\n",
      "print(prime_numbers)\n",
      "```\n",
      "\n",
      "이 코드를 실행하면 1부터 100까지의 소수인 숫자들이 리스트로 출력됩니다.\n"
     ]
    }
   ],
   "source": [
    "single_ask(\"1부터 100까지의 숫자 중 소수인 숫자를 모두 알려 줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9bf002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate():\n",
    "    while(1):\n",
    "        message = input('사람: ')\n",
    "        message = message.strip()\n",
    "    \n",
    "        if message == '':\n",
    "            print('대화 내용을 입력하세요.')\n",
    "            continue\n",
    "        elif message == 'exit':\n",
    "            break\n",
    "    \n",
    "        # 대화 맥락을 고려하여 전체 최대 토큰을 초과하는지 체크하도록 한다.\n",
    "        total_cnt = check_tokens(context) + len(message)\n",
    "\n",
    "        if total_cnt >= MAX_TOKENS:\n",
    "            context.clear()\n",
    "            print('context cleared.')\n",
    "\n",
    "        # ChatGPT 대화를 위한 메시지 형태 설정하기\n",
    "        if len(context) == 0:\n",
    "            context.append({\"role\": \"system\", \"content\": \"너는 훌륭한 토론 선생님이야. 너와 나는 원자력 발전소 폐지에 대해 토론할 거야. 너는 내 의견에 반대 입장에서 토론해.\"})\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        response = openai.ChatCompletion.create(model=MODEL, messages=context, temperature=TEMPERATURE)\n",
    "\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "        print(f\"AI: {answer}\")\n",
    "        #codes = markdown.markdown(answer, extensions=['fenced_code', 'codehilite'])\n",
    "        context.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "        if check_tokens(context) >= MAX_TOKENS:\n",
    "            context.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22dc33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사람:  더 이상 원자력 발전소를 운영해서는 안 돼. 사고가 나면 피해도 심하고, 폐기물을 처리하는 것도 매우 어려워.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 원자력 발전소 운영과 관련된 안전과 폐기물 처리는 중요한 문제입니다. 원자력 발전소는 전기 생산에 대한 중요한 역할을 하지만, 안전과 환경 문제에 대한 우려도 있습니다. 이에 대한 대안적인 에너지 생산 방법을 고려하는 것이 중요합니다. \n",
      "\n",
      "1. 재생 에너지: 태양광, 풍력, 수력 등 재생 가능한 에너지원을 활용하는 것은 친환경적이고 지속 가능한 대안입니다. 이러한 에너지원은 환경에 미치는 영향이 적고, 폐기물 처리 문제도 적습니다.\n",
      "\n",
      "2. 에너지 효율: 에너지를 효율적으로 사용하는 것도 중요합니다. 에너지 절약을 위한 정책과 기술 개발을 통해 에너지 소비를 줄이고, 친환경적인 에너지 생산 방법을 활용할 수 있습니다.\n",
      "\n",
      "3. 탈원전 정책: 원자력 발전소를 단계적으로 폐쇄하고, 대안적인 에너지 생산 방법에 집중하는 탈원전 정책을 추진하는 것도 고려해볼 수 있습니다. 이를 위해 장기적인 전략과 계획이 필요합니다.\n",
      "\n",
      "4. 연구 및 개발: 친환경적이고 안전한 에너지 생산 방법에 대한 연구와 개발을 지원하고, 혁신적인 기술을 발전시키는 것도 중요합니다. 이를 통해 더욱 효율적이고 지속 가능한 에너지 생산 방법을 개발할 수 있습니다.\n",
      "\n",
      "원자력 발전소 운영과 관련된 문제를 고려하면서, 친환경적이고 안전한 대안적인 에너지 생산 방법을 추구하는 것이 중요합니다. 이는 우리의 환경과 안전을 보호하고, 지속 가능한 미래를 위한 선택입니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사람:  그럼 너도 장기적으로는 결국 원자력 발전소를 닫는 것에 대해 동의하는 거잖아. 탈원전을 주장하고 있잖아.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 저는 인공지능 어시스턴트로서 개인적인 의견을 가지고 있지 않습니다. 제 역할은 정보를 제공하고 도움을 주는 것입니다. 원자력 발전소 운영과 관련된 결정은 정부, 전문가 및 이해관계자들이 고려해야 할 복잡한 문제입니다. \n",
      "\n",
      "탈원전을 주장하는 사람들은 환경 및 안전 문제, 폐기물 처리 문제 등을 고려하여 원자력 발전소를 닫는 것을 주장합니다. 그러나 원자력 발전소는 전기 생산에 중요한 역할을 하고 있으며, 에너지 공급에 대한 안정성과 신뢰성을 제공하는 측면도 있습니다.\n",
      "\n",
      "이러한 문제에 대한 결정은 정책 결정자들과 전문가들이 과학적인 근거와 다양한 이해관계자들의 의견을 종합하여 고려해야 합니다. 이러한 결정은 에너지 공급의 장기적인 안정성, 환경 보호, 안전성, 경제적인 측면 등을 고려하여 이루어져야 합니다.\n",
      "\n",
      "따라서, 원자력 발전소 운영과 관련된 결정은 정책 결정자들과 전문가들이 고려해야 할 문제이며, 이에 대한 다양한 의견과 관점이 존재합니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사람:  그리고 네가 말한 것처럼 원전 말고 태양광이나 풍력을 쓰면 친환경적이고 오염이나 방사능의 문제도 피해갈 수 있어.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 맞습니다. 태양광 및 풍력과 같은 재생 가능한 에너지원은 친환경적이며, 환경 오염 및 방사능의 문제를 피할 수 있는 대안적인 에너지 생산 방법입니다. \n",
      "\n",
      "태양광 발전은 태양 에너지를 활용하여 전기를 생산하는 방법으로, 태양광 패널을 통해 태양 에너지를 직접 수집합니다. 이는 대기 오염, 온실 가스 배출 및 자원 소모를 줄일 수 있습니다.\n",
      "\n",
      "풍력 발전은 바람의 운동 에너지를 활용하여 전기를 생산하는 방법으로, 풍력터빈을 통해 바람의 운동을 회전 운동으로 변환합니다. 이는 대기 오염과 같은 환경 오염 문제를 줄이고, 지속 가능한 에너지 생산을 가능하게 합니다.\n",
      "\n",
      "재생 가능한 에너지원을 사용하면 환경에 미치는 영향을 최소화하고, 지속 가능한 에너지 공급을 실현할 수 있습니다. 또한, 에너지 생산에 대한 안정성과 신뢰성을 제공할 수 있습니다.\n",
      "\n",
      "그러나 재생 가능한 에너지원의 활용에도 일부 제약 사항이 있을 수 있으며, 에너지 저장 및 전송 문제 등에 대한 연구와 기술 개발이 필요합니다. 이러한 문제를 해결하기 위해 지속적인 연구와 혁신이 필요합니다.\n",
      "\n",
      "따라서, 태양광 및 풍력과 같은 재생 가능한 에너지원은 친환경적이고 오염 및 방사능의 문제를 피할 수 있는 대안적인 에너지 생산 방법으로 강조되고 있습니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사람:  exit\n"
     ]
    }
   ],
   "source": [
    "debate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1951c5",
   "metadata": {},
   "source": [
    "## 논증 분석을 위한 ChatGPT API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a7ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\"보기\"는 학생이 작성한 글이야. 툴민의 논증(Toulmin's Argumentation Pattern)에 따라 글에 포함되어 있는 주장(claim), 반박(rebuttal), 자료(data), 보장(warrant), 뒷받침(backing), 제한 조건(qualifer)이 명시적으로 포함되어 있는지 확인하고 추출해. \n",
    "만약 관련된 요소가 글 속에 포함되어 있지 않다면 '없음'으로 표시해. \n",
    "논증 요소의 정의는 다음과 같아.\n",
    "주장(claim): Assertions about what exists or values that people hold. \n",
    "자료(data): Statements that are used as evidence to support the claim. \n",
    "보장(warrant): Statements that explain the relationship of the data to the claim. \n",
    "제한 조건(qualifier): Special conditions under which the claim holds true. \n",
    "뒷받침(backing): Underlying assumptions that are often not made explicit. \n",
    "반박(rebuttal): Statements that contradict either the data, warrant, backing or qualifier of an argument. \n",
    "또한 학생의 논증에 대한 점수을 0점에서 5점까지로 평가하려고 해. 평가한 결과에 대한 점수와 함께 글을 더 잘 쓸 수 있도록 쉽고 구체적으로 피드백을 줘.\n",
    "채점 기준은 다음과 같아.\n",
    "0점: Argumentation does not include anything of elements.\n",
    "1점: Argumentation consists of arguments that are a simple claim versus a counter-claim or a claim versus a claim.\n",
    "2점: Argumentation has arguments consisting of a claim versus a claim with either data, warrants, or backings but do not contain any rebuttals.\n",
    "3점: Argumentation has arguments with a series of claims or counterclaims with either data, warrants, or backings with the occasional weak rebuttal.\n",
    "4점: Argumentation shows arguments with a claim with a clearly identifiable rebuttal. Such an argument may have several claims and counterclaims as well.\n",
    "5점: Argumentation displays an extended argument with more than one rebuttal.\n",
    "수행한 결과를 다음과 같은 형식으로 한글로 반환해 줘.\n",
    "주장:{결과}\n",
    "반박:{결과}\n",
    "자료:{결과}\n",
    "보장:{결과}\n",
    "뒷받침:{결과}\n",
    "제한 조건:{결과}\n",
    "점수:{결과}\n",
    "피드백:{결과}\n",
    "보기:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "015e691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['주장', '반박', '자료', '보장', '뒷받침', '제한 조건', '점수', '피드백']\n",
    "elements2 = ['claim', 'rebuttal', 'data', 'warrant', 'back', 'qualify', 'score', 'feedback']\n",
    "none_list = ['없습니다.', '없음.', '없습니다', '없음', '(없음)', '(없음.)', '(없음).', '(없습니다.)', '(없습니다)']\n",
    "\n",
    "def inspect_data(text):\n",
    "    is_first = True\n",
    "    \n",
    "    try:\n",
    "        text = text.strip()\n",
    "        print('Original:', text)\n",
    "        query_msg = query + text\n",
    "\n",
    "        # 메시지 설정하기\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": query_msg}\n",
    "        ]\n",
    "\n",
    "        # ChatGPT API 호출하기\n",
    "        response = openai.ChatCompletion.create(model=MODEL, messages=messages, temperature=TEMPERATURE)\n",
    "        answer = response.choices[0].message['content']\n",
    "        answer = answer.strip()\n",
    "\n",
    "        print(answer)\n",
    "\n",
    "        arguments = {}\n",
    "\n",
    "        for item in elements:\n",
    "            arguments[item] = ''\n",
    "\n",
    "        current_key = None\n",
    "\n",
    "        for line in answer.split('\\n'):\n",
    "            line = line.strip()\n",
    "            line = line.strip('\\n')\n",
    "\n",
    "            if line:\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    current_key = key.strip()\n",
    "                    value = value.strip()\n",
    "                    value = value.strip('\\n')\n",
    "                    arguments[current_key] = value\n",
    "                else:\n",
    "                    arguments[current_key] += ' ' + line.strip()\n",
    "\n",
    "        for key, value in arguments.items():\n",
    "            for item in none_list:\n",
    "                if item in value:\n",
    "                    arguments[key] = ''\n",
    "                    break\n",
    "\n",
    "        updated_arguments = {}\n",
    "        for key, value in arguments.items():\n",
    "            for item in elements:\n",
    "                if item in key:\n",
    "                    new_key = item\n",
    "                    break\n",
    "                else:\n",
    "                    new_key = key\n",
    "\n",
    "            updated_arguments[new_key] = value\n",
    "\n",
    "        cleaned_arguments = {key.strip(\"[]\"): value for key, value in updated_arguments.items()}\n",
    "        if cleaned_arguments['점수'] == '':\n",
    "            cleaned_arguments['점수'] = 0\n",
    "        else:\n",
    "            cleaned_arguments['점수'] = int(re.sub(r'\\D', '', cleaned_arguments['점수']))\n",
    "\n",
    "        for i in range(len(elements)):\n",
    "            cleaned_arguments[elements2[i]] = cleaned_arguments.pop(elements[i])\n",
    "\n",
    "    except openai.error.APIError as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        \n",
    "    except openai.error.APIConnectionError as e:\n",
    "        #Handle connection error here\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "        \n",
    "    except openai.error.RateLimitError as e:\n",
    "        #Handle rate limit error (we recommend using exponential backoff)\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "    \n",
    "    return cleaned_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b51ce3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = '''유진이는 부산에서 태어났다. 왜냐하면 부산에서 태어난 사람은 일반적으로 대한민국 국민일 것이기 때문이다.\n",
    "다음과 같은 법조항과 규정들을 근거로(국적법). 그래서 그의 부모가 외국인이었거나 그가 귀화한 미국인이 된 경우가 아니라면 유진이는 한국인이다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bec6315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 유진이는 부산에서 태어났다. 왜냐하면 부산에서 태어난 사람은 일반적으로 대한민국 국민일 것이기 때문이다.\n",
      "다음과 같은 법조항과 규정들을 근거로(국적법). 그래서 그의 부모가 외국인이었거나 그가 귀화한 미국인이 된 경우가 아니라면 유진이는 한국인이다.\n",
      "주장: 유진이는 한국인이다.\n",
      "반박: 없음\n",
      "자료: 유진이는 부산에서 태어났다.\n",
      "보장: 부산에서 태어난 사람은 일반적으로 대한민국 국민일 것이다.\n",
      "뒷받침: 없음\n",
      "제한 조건: 없음\n",
      "점수: 3\n",
      "피드백: 학생의 논증은 일부 요소를 포함하고 있지만, 반박이나 뒷받침이 없어서 약한 논증으로 평가됩니다. 논증을 강화하기 위해 추가적인 자료나 보장을 제시하고, 가능하다면 반박을 고려해 보세요.\n"
     ]
    }
   ],
   "source": [
    "result_dict = inspect_data(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b9a8d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': '유진이는 한국인이다.',\n",
       " 'rebuttal': '',\n",
       " 'data': '유진이는 부산에서 태어났다.',\n",
       " 'warrant': '부산에서 태어난 사람은 일반적으로 대한민국 국민일 것이다.',\n",
       " 'back': '',\n",
       " 'qualify': '',\n",
       " 'score': 3,\n",
       " 'feedback': '학생의 논증은 일부 요소를 포함하고 있지만, 반박이나 뒷받침이 없어서 약한 논증으로 평가됩니다. 논증을 강화하기 위해 추가적인 자료나 보장을 제시하고, 가능하다면 반박을 고려해 보세요.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8549db3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e34a5e",
   "metadata": {},
   "source": [
    "## 네이버 뉴스 기사를 불러와서 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59267d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://n.news.naver.com/mnews/article/003/0012024087?sid=101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2312f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def summarize(url=None, text=None):\n",
    "    if (url is None) and (text is None):\n",
    "        print('URL 또는 분석할 텍스트를 입력해 주세요.')\n",
    "        return\n",
    "    \n",
    "    # 현재는 네이버 뉴스 기사만 가지고 옴\n",
    "    if url is not None:\n",
    "        req = requests.get(url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        text = soup.select_one('article#dic_area.go_trans._article_content').text\n",
    "        text = text.strip()\n",
    "    \n",
    "    # 메시지 설정하기\n",
    "    query = f\"주어진 텍스트의 내용을 요약해 줘. 텍스트:{text}\"\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    # ChatGPT API 호출하기\n",
    "    response = openai.ChatCompletion.create(model=MODEL, messages=messages, temperature=TEMPERATURE)\n",
    "    answer = response.choices[0].message['content']\n",
    "    answer = answer.strip()\n",
    "\n",
    "    print('입력된 텍스트')\n",
    "    print(text)\n",
    "    print('요약:')\n",
    "    print(answer)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd0dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력된 텍스트\n",
      "LED 사업부 '알에프엘이디'로 물적 분할\"이차전지·반도체 사업 강화\"\n",
      "\n",
      "\n",
      "\n",
      "[서울=뉴시스] 김경택 기자 = 코스닥 상장사 알에프세미가 LED 조명 사업부문을 떼내는 물적분할을 결정했다. 기존 반도체 사업과 함께 신사업을 추진 중인 이차전지 사업에 보다 집중한다는 목표다.10일 금융투자업계에 따르면 알에프세미는 전날 LED 조명 사업부문을 별도 법인으로 떼내는 물적분할을 결정했다고 공시했다. 이번 분할은 존속회사가 분할신설회사 발행주식의 100%를 배정받는 물적분할 방식으로 추진된다. 분할기일은 10월24일로 회사 측은 다음 달 19일 임시주주총회를 통해 물적분할 안건을 승인할 예정이다. 분할된 LED 조명사업은 신설법인 '알에프엘이디(RFLED)'가 맡게 되며, 알에프세미가 비상장 법인 알에프엘이디를 100% 지배한다. 알에프세미는 기존 반도체 사업과 추진 중인 이차전지 신규 사업에 보다 집중할 수 있을 전망이다.회사 측은 분할 목적에 대해 사업의 전문성을 제고하고 경쟁력을 강화하기 위한 것이라고 밝혔다. 회사 측은 \"존속법인인 알에프세미는 새로운 성장동력 또는 기존 사업과 시너지가 높은 신사업을 발굴하고 투자해 시장환경의 변화에 신속히 대응해 기업가치와 주주가치를 제고하는 것이 목표\"라면서 \"신설법인인 알에프엘이디의 경우 핵심 사업에 집중 투자를 하고, 시장의 상황 등을 고려해 필요할 경우 외부 투자유치, 전략적 사업 제휴, 기술 협력 등을 통해 경쟁력 강화와 재무구조 개선을 도모할 예정\"이라고 설명했다.회사 관계자는 \"반도체와 LED 사업부 간의 별다른 시너지가 없고, 신사업에 집중하기 위해 이번 물적분할을 진행했다\"며 \"각 법인이 보유한 강점을 극대화해 기업가치에 반영될 수 있도록 노력할 것\"이라고 말했다.이번 물적분할에 반대하는 주주는 주식매수청구권을 행사할 수 있다. 매수예정가격은 1만4737원으로 전일 종가 대비 40% 이상 높은 수준이다. 다음 달 19일부터 10월9일까지 주식매수청구 신청을 접수할 예정이다. 다만 주식매수가액의 합계액이 50억원을 넘을 경우 회사 측의 분할결정 철회가 가능하다.한편 알에프세미는 지난 6월 최대주주가 진평전자로 변경됐다. 이후 반도체 소자 사업을 기반으로 LFP(리튬인산철) 배터리 사업에 진출했다. 지난달에는 관계사 산시란완진평 생산법인이 알에프세미에 이차전지 생산기지로서 LFP 배터리 본격적인 공급을 시작했다.회사 관계자는 \"최대주주 변경 후 주주가치 제고를 위한 다양한 사업적, 정책적 방안을 고려 중\"이라며 \"재무구조 안정화 후 경영 효율화를 위해 알에프엘이디의 물적분할을 포함한 다양한 방안도 검토하고 있다\"고 강조했다．\n",
      "요약:\n",
      "알에프세미는 LED 조명 사업부문을 떼내는 물적 분할을 결정했다. 이를 통해 기존 반도체 사업과 함께 이차전지 사업에 집중할 예정이다. 분할된 LED 조명 사업은 알에프엘이디라는 신설 법인으로 이관되며, 알에프세미가 비상장 법인 알에프엘이디를 100% 지배한다. 이번 분할은 사업의 전문성을 제고하고 경쟁력을 강화하기 위한 것으로 이루어진다. 주주는 주식매수청구권을 행사할 수 있으며, 매수예정가격은 전일 종가 대비 40% 이상 높은 수준이다. 알에프세미는 최대주주 변경 후 주주가치 제고를 위한 다양한 사업적, 정책적 방안을 고려 중이다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'알에프세미는 LED 조명 사업부문을 떼내는 물적 분할을 결정했다. 이를 통해 기존 반도체 사업과 함께 이차전지 사업에 집중할 예정이다. 분할된 LED 조명 사업은 알에프엘이디라는 신설 법인으로 이관되며, 알에프세미가 비상장 법인 알에프엘이디를 100% 지배한다. 이번 분할은 사업의 전문성을 제고하고 경쟁력을 강화하기 위한 것으로 이루어진다. 주주는 주식매수청구권을 행사할 수 있으며, 매수예정가격은 전일 종가 대비 40% 이상 높은 수준이다. 알에프세미는 최대주주 변경 후 주주가치 제고를 위한 다양한 사업적, 정책적 방안을 고려 중이다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaab5aa",
   "metadata": {},
   "source": [
    "## 특정 PDF를 읽어들이고 이에 대해 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ab87737-7fde-430e-81e6-f4ed748eb354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (3.0.1)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/heavenly/opt/anaconda3/envs/flask/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-macosx_11_0_arm64.whl (924 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.4/924.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c022101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab2eda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 읽고 싶은 파일의 위치를 지정하도록 한다.\n",
    "reader = PdfReader(\"personal/the scientific method as myth and ideal.pdf\")\n",
    "\n",
    "raw_text = \"\"\n",
    "\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6364dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8f0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e722302f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This article examines the popular conception of the scientific method and argues that it should be discarded rather than treated as an ideal or approximation. It surveys the history of the concept and the criticisms of it, and suggests that lessons can be learned from considering the shortcomings of the myth. It also discusses the implications for introductory pedagogical contexts, the importance of collaboration in the scientific process, the classical inductivist view, hypothetico-deductivism, Bayesian Confirmation Theory, Inference to the Best Explanation, data-mining, methodological pluralism, and the differences between scientific hypotheses and questions. It argues that the scientific method should be seen as a pluralistic approach to reasoning, and that the focus should be on the various methods, tools, and values of scientific activity.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_document_chain.run(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ebfde",
   "metadata": {},
   "source": [
    "## 여러 개의 파일에 대한 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e28ae48-053b-4578-85c3-74ea2a578b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-3.17.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cc1369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"personal/dynamic social representations.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #chunk overlap seems to work better\n",
    "documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edfd7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 22 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(documents)} document(s) in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a481d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', max_retries=20, openai_api_key = OPENAI_API_KEY)\n",
    "vectorstore2 = Chroma.from_documents(documents, embeddings) # 벡터화된 DB\n",
    "model = ChatOpenAI(temperature=TEMPERATURE, model_name=MODEL, openai_api_key = OPENAI_API_KEY)\n",
    "qa = ConversationalRetrievalChain.from_llm(model, vectorstore2.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a87e535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    result = qa({\"question\":question, \"chat_history\":[]})\n",
    "    print(result['answer'])\n",
    "    \n",
    "    return result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f26d0fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문의 핵심 주장은 2009 H1N1 대유행 기간 동안 사람들의 인식 패턴이 변화하고, 피해자, 악당, 영웅의 역할이 안정적인지 혹은 변동하는지를 조사하였다는 것입니다. 논문은 대유행 기간 동안 수집된 인터뷰 자료와 언론 보도 자료를 분석하여 사람들의 인식 변화를 확인하고, 언론 보도가 인터뷰 자료에 영향을 미치는지도 조사하였습니다. 논문은 또한 사람들과 언론의 인식 패턴이 멀리 떨어진 집단에서 지역적인 집단으로의 관심 변화를 보였으며, 언론 보도와 사람들의 인식 패턴이 유사한 경향을 보였다고 언급하고 있습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이 논문의 핵심 주장은 2009 H1N1 대유행 기간 동안 사람들의 인식 패턴이 변화하고, 피해자, 악당, 영웅의 역할이 안정적인지 혹은 변동하는지를 조사하였다는 것입니다. 논문은 대유행 기간 동안 수집된 인터뷰 자료와 언론 보도 자료를 분석하여 사람들의 인식 변화를 확인하고, 언론 보도가 인터뷰 자료에 영향을 미치는지도 조사하였습니다. 논문은 또한 사람들과 언론의 인식 패턴이 멀리 떨어진 집단에서 지역적인 집단으로의 관심 변화를 보였으며, 언론 보도와 사람들의 인식 패턴이 유사한 경향을 보였다고 언급하고 있습니다.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('이 논문의 핵심 주장이 뭐야?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d16a1",
   "metadata": {},
   "source": [
    "## 여러 개의 논문을 대상으로 한 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0b2c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a433f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'wos_gifted_db'\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', max_retries=20, openai_api_key = OPENAI_API_KEY)\n",
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1772af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=TEMPERATURE, model_name=MODEL, openai_api_key = OPENAI_API_KEY)\n",
    "qa = ConversationalRetrievalChain.from_llm(model, vectorstore.as_retriever(search_kwargs={\"k\": 3}), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3d645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c12cd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_history(lists):    \n",
    "    tot_size = 0\n",
    "    if len(lists) >= 1:\n",
    "        for item in lists:\n",
    "            tot_size += len(item.content)\n",
    "\n",
    "        if tot_size >= 3000:\n",
    "            lists = lists[2:]  # chat_history 전역 변수를 수정\n",
    "        \n",
    "        return lists\n",
    "    else:\n",
    "        return lists\n",
    "        \n",
    "def questioning(lists, query):\n",
    "    lists = manage_history(lists)\n",
    "    \n",
    "    result = qa({\"question\": query, \"chat_history\": lists})\n",
    "    print(result['answer']) # 응답 출력\n",
    "        \n",
    "    #Reference 출력\n",
    "    refs = []\n",
    "    print('Reference:')\n",
    "    for item in result['source_documents']:\n",
    "        filename_with_extension = os.path.basename(item.metadata['source'])\n",
    "        filename = os.path.splitext(filename_with_extension)[0]\n",
    "        print(filename)\n",
    "        refs.append(filename)\n",
    "        \n",
    "    lists.append(HumanMessage(content=query, additional_kwargs={}, example=False))\n",
    "    lists.append(AIMessage(content=result['answer'], additional_kwargs={'source':refs}, example=False))\n",
    "        \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0883e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과학영재를 선발할 때 기준은 국가나 기관에 따라 다를 수 있습니다. 일반적으로는 학업 성적, 과학적 업적, 창의력, 문제 해결 능력, 실험 및 연구 경험 등이 고려되는 경우가 많습니다. 또한, 대회나 시험을 통해 실력을 평가하는 경우도 있을 수 있습니다. 선발 기준은 각 기관이나 국가의 정책에 따라 다르므로, 구체적인 정보를 얻기 위해서는 해당 기관이나 국가의 공식 웹사이트나 관련 담당자에게 문의하는 것이 가장 좋습니다.\n",
      "Reference:\n"
     ]
    }
   ],
   "source": [
    "chat_history = questioning(chat_history, \"과학영재를 선발할 때 기준은 무엇일까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eac284dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과학영재 교육은 일반적으로 초등학교 중학년부터 시작하는 것이 좋습니다. 이 시기에 학생들은 기본적인 과학 개념을 이해하고 실험을 통해 문제 해결 능력을 키울 수 있습니다. 그러나 어린 학생들도 과학에 흥미를 가질 수 있으므로, 학교나 지역 사회에서 제공하는 과학 교육 프로그램에 참여하는 것도 좋은 방법입니다.\n",
      "Reference:\n"
     ]
    }
   ],
   "source": [
    "chat_history = questioning(chat_history, \"과학영재 교육은 몇 살 때부터 시작하는 것이 좋을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3546015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과학영재를 선발할 때 고려해야 하는 조건은 다양할 수 있습니다. 일반적으로는 다음과 같은 요소들이 고려될 수 있습니다:\n",
      "\n",
      "1. 학업 성적: 과학 분야에서의 우수한 학업 성적은 과학영재로서의 잠재력을 나타낼 수 있습니다.\n",
      "\n",
      "2. 창의력과 문제 해결 능력: 과학영재는 창의적인 사고와 문제 해결 능력을 갖추고 있어야 합니다.\n",
      "\n",
      "3. 과학적 호기심과 열정: 과학에 대한 호기심과 열정이 있는 학생들이 과학영재로서 선발될 수 있습니다.\n",
      "\n",
      "4. 과학적 활동 참여: 학교나 지역사회에서 과학적인 활동에 참여한 경험이 있는지 여부도 고려될 수 있습니다.\n",
      "\n",
      "5. 추천서: 교사나 과학 분야 전문가로부터 받은 추천서도 선발 과정에서 고려될 수 있습니다.\n",
      "\n",
      "이는 일반적인 기준이며, 실제 선발 과정은 학교나 기관에 따라 다를 수 있습니다. 따라서, 선발 과정에 대한 자세한 정보는 해당 학교나 기관의 선발 지침을 참고하는 것이 좋습니다.\n",
      "Reference:\n"
     ]
    }
   ],
   "source": [
    "chat_history = questioning(chat_history, \"과학영재를 선발할 때 고려해야 하는 조건은 무엇일까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1315b7-9c4c-4cdc-9ab4-693d8efbf179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
